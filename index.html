<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 5.4.2">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.lug.ustc.edu.cn/css?family=Noto+Serif+SC:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.1/css/all.min.css" integrity="sha256-Z1K5uhUaJXA7Ll0XrZ/0JhX4lAtZFpT6jkKrEDT0drU=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"example.com","root":"/","images":"/images","scheme":"Gemini","darkmode":false,"version":"8.14.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"},"path":"/search.json","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false}}</script><script src="/js/config.js"></script>

    <meta property="og:type" content="website">
<meta property="og:title" content="Coder4nlp&#39;s Blog">
<meta property="og:url" content="http://example.com/index.html">
<meta property="og:site_name" content="Coder4nlp&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Coder4nlp">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="http://example.com/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>Coder4nlp's Blog</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Coder4nlp's Blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li><li class="menu-item menu-item-following"><a href="/following/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>following</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Coder4nlp</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">16</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/12/30/JIT/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Coder4nlp">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Coder4nlp's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Coder4nlp's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/12/30/JIT/" class="post-title-link" itemprop="url">“返璞归真”的JIT</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2025-12-30 12:05:41 / Modified: 12:49:17" itemprop="dateCreated datePublished" datetime="2025-12-30T12:05:41+08:00">2025-12-30</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>目前扩散模型通用的做法是：输入随机噪声，用预训练的VAE（变分自编码器）将它们压缩到一个“潜在空间”，然后运行扩散过程。在原始的高维像素上运行扩散通常被认为计算成本太高，或者在数学上不稳定。但MIT一篇由李Tianhong Li和Kaiming He合著的新论文表明，大家可能走错了方向。他们的论点非常简单：问题不在于像素的高维，问题是我们要求网络预测什么。</p>
<blockquote>
<p>流形假设 (The Manifold Assumption)</p>
<ul>
<li>自然数据流形： 世界上所有的真实照片，在巨大的像素空间（例如 $$256 \times 256 \times $$ 的维度）中，其实只分布在一个很小的、有规律的“薄片”上。比如，像素的随机组合有无数种，但能组成“猫”的组合极少。这个“薄片”就是流形 (Manifold)。</li>
<li>噪声的无序性： 噪声是杂乱无章的，它充满了整个高维空间，并不存在于低维流形上。</li>
<li>训练神经网络来预测干净图像（即$x$预测）与训练它来预测噪声或速度（即$ \epsilon&#x2F;v$λ 预测）有着根本的不同。</li>
</ul>
</blockquote>
<p><img src="/2025/12/30/JIT/1.PNG"></p>
<p>既然我们最终要的是清晰图像，而且清晰图像是有规律（流形）的，那为什么不让 Transformer 直接去预测图像本身呢？基于流形假设，作者认为应该<strong>预测清晰数据：模型的目标永远是那个“低维流形”。即使网络容量（参数量）看似不足，但因为它只需要寻找有规律的流形，所以它能更有效地处理高维像素。</strong></p>
<h3 id="扩散模型"><a href="#扩散模型" class="headerlink" title="扩散模型"></a>扩散模型</h3><p>扩散模型的核心思想是通过预定义的过程，逐步像图片种注入噪声，然后训练一个神经网络来逆转这个过程。扩散模型的预测，可以在$x,v,\epsilon$​三种空间进行。在已知 $z_t$和$t$下，这三个未知数只要确定了其中<strong>任意一个</strong>，另外两个就能通过代数运算推导出来。</p>
<ol>
<li>$x$：最终要还原的清洁数据（终点）。</li>
<li>$\epsilon$：随机噪声（起点）。</li>
<li>$v$：当前移动的速度向量（方向）。</li>
</ol>
<p>三种预测方式在数学上是等价的，但实际上神经网络预测这三种目标的难度是不一样的。由于损失空间和神经网络输出空间可以不同，这样组合下来有9种选择。</p>
<p>我们以基于流的范式来表述，即在$v$空间中，作为一个更简单的起点，然后讨论其他空间。</p>
<p>基于线性插值来生成带噪声的样本</p>
<p>$$z_t&#x3D;tx+(1-t) \epsilon$$</p>
<p>$x$：真实数据。</p>
<p>$\epsilon$$：纯噪声（来自标准正态分布 $$N(0, I)$）。</p>
<p>$t$：时间轴，范围从 $[0, 1]$。</p>
<ul>
<li>当 $t&#x3D;0$ 时：$z_0 &#x3D; \epsilon$（完全是噪声）。</li>
<li>当 $t&#x3D;1$ 时：$z_1 &#x3D; x$（完全是真实数据）。</li>
</ul>
<p><strong>速度定义</strong></p>
<p>$$v &#x3D; x - \epsilon$$</p>
<ul>
<li><strong>物理意义</strong>：既然 $z_t$ 是随时间变化的位移，那么它的导数 $z_t’$ 就是移动的<strong>速度</strong>。</li>
<li><strong>推导</strong>：对 $z_t &#x3D; t x + (1-t) \epsilon$ 关于 $t$ 求导，得到 $1 \cdot x + (-1) \cdot \epsilon$，即 $x - \epsilon$。</li>
<li><strong>直观理解</strong>：速度 $v$ 就是从“起点（噪声）”指向“终点（数据）”的方向向量。</li>
</ul>
<p>在已知 $$z_t$$和$$t$$下，这三个未知数只要确定了其中<strong>任意一个</strong>，另外两个就能通过代数运算完美出来。</p>
<p><img src="/2025/12/30/JIT/2.PNG"></p>
<h2 id="小实验验证"><a href="#小实验验证" class="headerlink" title="小实验验证"></a>小实验验证</h2><p>为了验证神经网络应该直接预测清晰数据的论点。作者训练了一个具有 5 层的 ReLU 多层感知机（MLP），其隐藏单元维度为 256，并将其作为生成器。</p>
<p>作者做了一个巧妙的对比实验：</p>
<ul>
<li>$$d&#x3D;$$：这是数据的“元素维度”（比如只有两个参数控制形状），方便可视化。</li>
<li>$D$：这是模型“看到的维度”（通过一个随机矩阵 $P$ 把 2 维投影到 $D$ 维）。</li>
<li><strong>实验设置</strong>：当 $D$ 变大（从 2 变到 512）时，看三种预测空间的效果。</li>
</ul>
<p>实验结果发现：</p>
<ol>
<li>$x-prediction$ (预测数据)：哪怕到了 $D&#x3D;512$，模型依然能精准还原数据。</li>
<li>$v&#x2F; \epsilon$-prediction (预测速度&#x2F;噪声)：当 $D&#x3D;16$ 时就开始吃力，到了 $D&#x3D;512$ 直接<strong>彻底崩溃</strong>。</li>
</ol>
<p><img src="/2025/12/30/JIT/3.PNG"></p>
<h2 id="Just-Image-Transformers"><a href="#Just-Image-Transformers" class="headerlink" title="Just Image Transformers"></a>Just Image Transformers</h2><p>进一步的，作者采用没有VAE、U-Net、没有重构损失，仅仅使用一个作用于原始像素的标准视觉Transformer来进行实验。</p>
<p>架构非常简单：</p>
<ul>
<li>输入：将图像分成小块（例如，16 x 16像素）。</li>
<li>处理：将展平的patch（每个768个尺寸）送入Transformer.。</li>
<li>目标：直接预测干净像素（x-prediction）。</li>
</ul>
<p><img src="/2025/12/30/JIT/4.PNG"></p>
<h3 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h3><p><img src="/2025/12/30/JIT/5.PNG"></p>
<p><strong>这里需要特别注意的是</strong>，只在 Transformer 的 patch size 比较大 时，预测清晰图像才比预测速度更好。在patch size为4时，预测不同的空间差异并不大。最好的结果反而是预测速度空间，FID为3.46。</p>
<p><img src="/2025/12/30/JIT/6.PNG"></p>
<p>图 7（上）表明，尽管 $v$ 预测似乎是 $v$损失的“原生”参数化形式，但其损失值（约 25%）仍明显高于 $x$ 预测。这一对比表明，由于数据位于低维流形上，$x$ 预测任务本质上更简单。我们还观察到，未在此处展示的$ ϵ$ 预测的损失值约为 $x$ 预测的 3 倍，且不稳定，这或许可以解释其在表 2(a) 中的失败。图 7（下）比较了对应于两条训练曲线的去噪图像。对于 $x$ 预测，去噪图像即为 $xθ$ &#x3D; $netθ$；对于 $v$ 预测，去噪图像为 $xθ &#x3D; (1 - t)netθ + zt$，其中 $vθ &#x3D; netθ（见表 1(c)(1)）。图 7（上）中 v 预测的较高损失值在图 7（下）中表现为明显的伪影。请注意，图 7（下）中的伪影仅来自单次去噪步骤。在生成过程中，这种误差会在多步 ODE 求解器中累积，从而导致表 2(a) 中的灾难性失败。</p>
<h3 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h3><p>基于以上分析，作者最终采用的算法是预测$x-pred+v-loss$</p>
<p>优化目标为</p>
<p>$$\mathcal{L} &#x3D; \mathbb{E}_{t, \mathbf{x}, \epsilon} \left| \mathbf{v}_\theta(\mathbf{z}_t, t) - \mathbf{v} \right|^2, \ \text{where: } \mathbf{v}_\theta(\mathbf{z}_t, t) &#x3D; (\text{net}_\theta(\mathbf{z}_t, t) - \mathbf{z}_t) &#x2F; (1 - t).$$</p>
<h3 id="训练过程"><a href="#训练过程" class="headerlink" title="训练过程"></a>训练过程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Algorithm 1 Training step</span></span><br><span class="line"><span class="comment"># net(z, t): JiT network</span></span><br><span class="line"><span class="comment"># x: training batch</span></span><br><span class="line">t = sample t()</span><br><span class="line">e = randn like(x)</span><br><span class="line">z = t * x + (<span class="number">1</span> - t) * e</span><br><span class="line">v = (x - z) / (<span class="number">1</span> - t)</span><br><span class="line">x_pred = net(z, t)</span><br><span class="line">v_pred = (x_pred - z) / (<span class="number">1</span> - t)</span><br><span class="line">loss = l2 loss(v - v_pred)</span><br></pre></td></tr></table></figure>

<h3 id="采样过程"><a href="#采样过程" class="headerlink" title="采样过程"></a>采样过程</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Algorithm 2 Sampling step (Euler)</span></span><br><span class="line"><span class="comment"># z: current samples at t</span></span><br><span class="line">x_pred = net(z, t)</span><br><span class="line">v_pred = (x_pred - z) / (<span class="number">1</span> - t)</span><br><span class="line">z_next = z + (t_next - t) * v_pre</span><br></pre></td></tr></table></figure>

<h3 id="总结与思考"><a href="#总结与思考" class="headerlink" title="总结与思考"></a>总结与思考</h3><ul>
<li>这种方法如果能scale成功，将意味着我们可能不再需要复杂的 Latent Space（潜空间）或 VAE 编码器，直接用最基础的 Transformer 就能在超高分辨率下生成高质量图像。</li>
<li>在多模态理解上，主流的模型结构都需要一个视觉vit，可以类似的去掉Vit结构，直接像素输入。这个模型结构就变成了Fuyu，已经成功验证不要Vit的可行性</li>
<li>如果多模态理解不要VIT，生成不要VAE，这样极简的结构显得更加优雅</li>
<li>我已经想好统一多模态模型的论文题目了：<ul>
<li>Just Pixel Transformer (JPT)</li>
<li>Just Unified Transformer (JUT）</li>
<li>Just Sequence Transformer (JST）</li>
<li>Native Pixel Transformer (NPT)</li>
<li>OmniPatch</li>
</ul>
</li>
<li>直接像素的优势：<ul>
<li>极简的系统设计：由于没有 VAE 和 ViT，不需要处理复杂的感知损失（Perceptual Loss）或对抗损失（GAN Loss）</li>
<li>避免细节丢失：传统的 ViT 往往会丢失图像中的细节（比如文字、细小线条）。直接输入像素序列可以让 Transformer 自行学习如何捕捉空间关系，理论上能保留 100% 的原始视觉信息。</li>
<li>端到端的处理：整个模型（视觉 + 文本）在同一个梯度链条下训练，没有“冻结的编码器”带来的限制，视觉理解和逻辑推理能更好地融合。</li>
</ul>
</li>
<li>直接像素可能的问题：<ul>
<li>序列长度爆炸（计算复杂度）</li>
<li>确实先验知识：ViT 或 VAE 具有处理图像的先验知识（如局部相关性）。纯 Transformer 需要消耗更多的数据才能学到“相邻的像素构成了物体”这种常识。</li>
<li>训练难度：直接从像素学习高层语义（如“猫”的概念）比从预训练好的 ViT 特征中学习要难得多。</li>
</ul>
</li>
<li>可能缓解的方式：<ul>
<li>通过patch merge来降低序列长度</li>
<li>了处理高分辨率，可以引入局部窗口注意力（Local Attention）或线性注意力</li>
</ul>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/12/28/Z-Image/test/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Coder4nlp">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Coder4nlp's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Coder4nlp's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/12/28/Z-Image/test/" class="post-title-link" itemprop="url">Untitled</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2025-12-28 22:18:42 / Modified: 22:46:41" itemprop="dateCreated datePublished" datetime="2025-12-28T22:18:42+08:00">2025-12-28</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">graph TD</span><br><span class="line">    %% 定义节点样式</span><br><span class="line">    classDef startEnd fill:#e1f5fe,stroke:#0288d1,stroke-width:2px,rx:10,ry:10;</span><br><span class="line">    classDef brain fill:#f3e5f5,stroke:#8e24aa,stroke-width:3px,rx:5,ry:5;</span><br><span class="line">    classDef tools fill:#fff3e0,stroke:#ef6c00,stroke-width:1px,stroke-dasharray: 5 5;</span><br><span class="line">    classDef process fill:#ffffff,stroke:#333,stroke-width:1px;</span><br><span class="line"></span><br><span class="line">    %% 主要流程节点</span><br><span class="line">    Input([用户输入帖子&lt;br&gt;User Post]):::startEnd --&gt; Agent[智能体&lt;br&gt;Agent (LLM Orchestrator)]:::brain;</span><br><span class="line"></span><br><span class="line">    %% 工具子图区域</span><br><span class="line">    subgraph ToolSet [工具调用层 Tool Layer]</span><br><span class="line">        direction LR</span><br><span class="line">        Retrieval[检索工具&lt;br&gt;Retrieval Tool&lt;br&gt;(搜索梗/模板/上下文)]:::process</span><br><span class="line">        T2I[文生图工具&lt;br&gt;T2I Gen Tool&lt;br&gt;(图像生成模型)]:::process</span><br><span class="line">    end</span><br><span class="line"></span><br><span class="line">    %% Agent与工具的交互循环</span><br><span class="line">    Agent -- &quot;1. 分析意图，查询背景/模板&quot; --&gt; Retrieval;</span><br><span class="line">    Retrieval -- &quot;2. 返回相关上下文数据&quot; --&gt; Agent;</span><br><span class="line"></span><br><span class="line">    Agent -- &quot;3. 构建详细图像Prompt &amp; 文字内容&quot; --&gt; T2I;</span><br><span class="line">    T2I -- &quot;4. 生成图像并返回&quot; --&gt; Agent;</span><br><span class="line"></span><br><span class="line">    %% 最终输出</span><br><span class="line">    Agent -- &quot;5. 最终合成与审核&quot; --&gt; Output([输出表情包&lt;br&gt;Meme Output]):::startEnd;</span><br><span class="line"></span><br><span class="line">    %% 添加注释说明</span><br><span class="line">    note_agent[Agent核心职能:&lt;br&gt;1. 理解用户情绪与梗&lt;br&gt;2. 决定是否需要检索&lt;br&gt;3. 编写绘画提示词&lt;br&gt;4. 决定表情包文字]</span><br><span class="line">    note_agent -.- Agent</span><br><span class="line"></span><br><span class="line">    %% 连接线样式调整</span><br><span class="line">    linkStyle 1,2,3,4 stroke-width:2px,fill:none,stroke:blue;</span><br></pre></td></tr></table></figure>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/12/08/Z-Image/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Coder4nlp">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Coder4nlp's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Coder4nlp's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/12/08/Z-Image/" class="post-title-link" itemprop="url">Z-Image深度解析：60亿参数模型如何以效率挑战巨头Nano Banana Pro</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2025-12-08 19:40:54 / Modified: 22:34:43" itemprop="dateCreated datePublished" datetime="2025-12-08T19:40:54+08:00">2025-12-08</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p><img src="/2025/12/08/Z-Image/1.PNG"></p>
<blockquote>
<p>打破“唯规模论”，Z-Image的高效之道</p>
</blockquote>
<h2 id="唯规模论的挑战"><a href="#唯规模论的挑战" class="headerlink" title="唯规模论的挑战"></a>唯规模论的挑战</h2><p>在当前高性能文生图（Text-to-Image）领域，一场关于模型规模的“军备竞赛”正愈演愈烈。无论是顶级的闭源商业模型，还是如Qwen-Image（20B）、FLUX.2（32B）和Hunyuan-Image-3.0（80B）等领先的开源项目，其发展路径似乎都遵循着一条不成文的法则——“唯规模论”。然而，性能的提升往往伴随着高昂得令人望而却步的训练与推理成本，这已成为阻碍技术普及与创新的巨大障碍。</p>
<p>与此同时，业界浮现出另一条看似高效的捷径：依赖从强大的闭源模型中蒸馏出的合成数据进行训练。尽管这种方法能在资源有限的情况下快速提升性能，但它也带来了潜在的风险——形成一个封闭的反馈循环，可能导致错误累积和数据同质化，从而扼杀了超越教师模型范畴的创新能力。</p>
<p>在这一背景下，<strong>Z-Image</strong>应运而生。它不仅挑战了“不惜一切代价扩大规模”的范式，更摒弃了对合成数据蒸馏的依赖。Z-Image的核心论点清晰而有力：通过对<strong>数据</strong>、<strong>架构</strong>、<strong>训练</strong>和<strong>推理</strong>全生命周期的系统性优化，完全可以用更精简的资源，在纯粹的真实世界数据上，实现与巨头相媲美甚至超越的顶尖性能。</p>
<p>Z-Image的成就，通过一系列惊人的数据得以体现：</p>
<p>• <strong>高效的成本控制</strong>：仅用 <strong>31.4万 H800 GPU小时</strong>（约合63万美元）便完成了从零到一的完整训练，将顶尖模型的训练成本拉至前所未有的亲民水平。</p>
<p>• <strong>精简的模型规模</strong>：模型参数仅为 <strong>60亿</strong>，远小于动辄数百亿的竞争对手，为在消费级硬件上的部署与微调打开了大门。</p>
<p>• <strong>卓越的性能表现</strong>：在写实图像生成和极具挑战性的双语（中&#x2F;英）文本渲染方面，其性能媲美甚至超越了部分顶级的商业闭源模型。</p>
<p>• <strong>开放的社区贡献</strong>：为推动技术民主化，Z-Image的模型代码、权重和在线演示均已公开发布，赋能更广泛的开发者与研究者。</p>
<p>本文将深入剖析Z-Image实现这一系列突破背后的四大技术支柱，为读者系统性地揭示其如何在资源效率与模型性能之间找到最优解，为高效能AIGC（AI-Generated Content）的发展开辟一条全新的路径。</p>
<h2 id="Z-Image理念：系统性优化的四大支柱"><a href="#Z-Image理念：系统性优化的四大支柱" class="headerlink" title="Z-Image理念：系统性优化的四大支柱"></a>Z-Image理念：系统性优化的四大支柱</h2><ol>
<li><p><strong>高效的数据基础设施</strong> 这不仅是对数据进行简单的清洗与筛选，而是构建了一个动态的、以“最大化单位时间知识获取率”为目标的智能数据引擎。它确保每一单位的计算资源都能从数据中汲取最大化的信息增益，为模型的性能上限奠定了坚实基础。</p>
</li>
<li><p><strong>高效的S3-DiT架构</strong> 借鉴大语言模型（LLM）的成功经验，Z-Image采用了一种创新的单流（Single-Stream）扩散变换器架构。这种设计实现了极致的参数效率，并将文本、图像生成与图像编辑等多模态任务在统一框架下无缝集成，显著提升了模型的通用性与可扩展性。</p>
</li>
<li><p><strong>高效的训练策略</strong> Z-Image的训练过程被设计成一套循序渐进的“智能课程”。它通过分阶段、有重点地引导模型从掌握基础知识到精通高级技能，再到对齐人类偏好，系统性地构建模型能力，从而避免了在无效或低效的学习路径上浪费宝贵的计算资源。</p>
</li>
<li><p><strong>高效的推理方案</strong> 通过引入先进的知识蒸馏技术，Z-Image衍生出Turbo版本。该方案在几乎不牺牲生成质量的前提下，将推理速度提升了十倍以上，使其能够在企业级GPU上实现亚秒级响应，并成功适配内存小于16GB的消费级硬件。</p>
</li>
</ol>
<p>接下来，对这四大支柱逐一进行深度解析，揭示Z-Image高效能背后的技术秘诀。</p>
<h3 id="（1）数据为先-——-构建智能高效的数据基础设施"><a href="#（1）数据为先-——-构建智能高效的数据基础设施" class="headerlink" title="（1）数据为先 —— 构建智能高效的数据基础设施"></a>（1）数据为先 —— 构建智能高效的数据基础设施</h3><p>在计算资源受限的前提下，<strong>数据策略必须从追求“数量”转向追求“效率”</strong>。Z-Image的数据基础设施并非一个静态的数据集，而是一个旨在<strong>最大化每单位算力信息增益</strong>的动态引擎，它直接决定了模型能力的上限。该基础设施由四大协同模块构成，共同确保了训练数据在概念上广博而不冗余，在质量上精纯且对齐。</p>
<p><strong>数据分析引擎 (Data Profiling Engine)</strong> 。该引擎是数据策略的量化基石，它从多个维度为海量原始数据建立档案。技术层面，它评估图像的物理属性，如<strong>感知哈希（pHash）</strong>、清晰度、<strong>压缩伪影</strong>、<strong>色偏</strong>和<strong>模糊度</strong>；审美层面，它利用经过专业标注训练的模型为图像的视觉吸引力打分；语义层面，它通过专门的视觉语言模型（VLM）为图像生成丰富的语义标签。这些多维度的元信息，使得构建程序化的、分阶段的训练课程成为可能，确保在模型发展的“正确阶段”使用“正确的数据”。</p>
<p> <strong>跨模态向量引擎 (Cross-modal Vector Engine)</strong> 。该引擎是保障数据多样性与非冗余性的核心。它通过大规模语义去重，有效清除了概念上重复的数据。为解决主流方法中<code>range_search</code>函数的严重可扩展性瓶颈，Z-Image团队创新性地将其替换为基于GPU加速流水线的<strong>高效k近邻（k-NN）搜索函数</strong>。这一工程上的巨大突破，使得处理速度达到了惊人的<strong>“在8块H800上每10亿条目仅需8小时”</strong>，极大地提升了去重效率。此外，其强大的跨模态检索能力成为诊断和修复模型缺陷的关键工具，能够快速定位并剔除导致问题的低质量数据簇，同时主动补充数据集中缺失的概念。</p>
<p> <strong>世界知识拓扑图 (World Knowledge Topological Graph)</strong> 。该知识图谱如同一座“语义罗盘”，为数据策展提供了结构化的指引。它通过层级化的方式组织世界知识，确保了数据在概念覆盖上的广度。在实际应用中，它可以识别出数据池中代表性不足的概念（例如，特定文化符号或稀有物体），并指导数据引擎进行靶向补充。此外，在训练过程中，它还支持精细化的“概念平衡采样”，通过动态调整不同概念数据的采样权重，确保模型能够均衡地学习，避免偏向常见概念。</p>
<p><strong>主动主动数据治理引擎(Active Curation Engine)</strong> 这个闭环系统将数据基础设施从一个被动的数据源转变为一个自我完善的动态系统。它通过“人机协同”（Human-in-the-Loop）的主动学习循环，持续提升数据质量。系统首先自动采样模型表现不佳或缺乏知识的案例，随后这些案例进入一个由AI和人类专家共同参与的标注与审核流程。高质量的标注数据不仅被用于优化数据策展模型本身，也反哺了知识图谱，形成了一个不断发现问题、解决问题并自我提升的良性循环，尤其在解决长尾分布问题上发挥了关键作用。</p>
<p>一个强大的数据基础设施不仅为文生图模型提供了高质量的“燃料”，更为其衍生能力（如图像编辑）的构建奠定了坚实基础。正是基于此，Z-Image才得以高效地拓展其功能边界。</p>
<h3 id="（2）精简强大-——-可扩展的单流S3-DiT架构"><a href="#（2）精简强大-——-可扩展的单流S3-DiT架构" class="headerlink" title="（2）精简强大 —— 可扩展的单流S3-DiT架构"></a>（2）精简强大 —— 可扩展的单流S3-DiT架构</h3><p><img src="/2025/12/08/Z-Image/2.PNG"></p>
<p>Z-Image架构设计的核心目标是效率与稳定性。为了实现这一目标，它借鉴了大语言模型中“decoder-only”架构的卓越可扩展性，选择了一条与主流双流（dual-stream）架构截然不同的技术路径，即<strong>可扩展的单流扩散变换器（Scalable Single-Stream Diffusion Transformer, S3-DiT）</strong>。</p>
<p>S3-DiT架构的核心特点可以总结如下：</p>
<p>• <strong>统一的单流设计</strong> 。该架构的最大创新在于将来自不同模态的tokens——包括文本、图像VAE编码和图像语义——在序列层面直接拼接，形成一个统一的输入流。与分别处理文本和图像的双流架构相比，这种“早期融合”的设计极大地促进了不同模态信息在模型每一层的深度交互与融合，从而显著提升了参数的利用效率。</p>
<p>• <strong>核心组件选择</strong>。 为了在性能与效率间取得平衡，模型选用了一系列轻量级但性能卓越的组件。文本编码器采用了仅40亿参数且具备强大双语能力的<code>Qwen3-4B</code>，而图像词元化则依赖于以高质量重建著称的<code>Flux VAE</code>。这些精挑细选的组件共同服务于整体架构的高效与高质量目标。</p>
<p>• <strong>训练稳定性保障</strong> 。为了确保60亿参数规模的模型在长时间的训练过程中保持稳定，S3-DiT集成了一系列先进的归一化技术。例如，通过引入<code>QK-Norm</code>和<code>Sandwich-Norm</code>，有效调节了注意力模块内部的激活值和信号幅度，从而避免了训练过程中可能出现的梯度爆炸或消失问题。</p>
<p>• <strong>对编辑任务的天然扩展性</strong>。 S3-DiT的统一序列处理方式使其天然具备处理复杂多模态任务的能力。在处理图像编辑等任务时，架构通过一种精巧的机制来区分源图像和目标图像：<strong>为它们的tokens分配对齐的空间RoPE坐标，但在时间维度上通过一个单位间隔偏移来区分。此外，模型还应用了不同的时间条件值</strong>，以区分干净的参考图像和带噪声的目标图像。这种设计无需修改核心架构，展现了极强的灵活性和可扩展性。</p>
<h3 id="（3）智能训练-——-从基础到卓越的渐进式课程"><a href="#（3）智能训练-——-从基础到卓越的渐进式课程" class="headerlink" title="（3）智能训练 —— 从基础到卓越的渐进式课程"></a>（3）智能训练 —— 从基础到卓越的渐进式课程</h3><p><img src="/2025/12/08/Z-Image/4.PNG"></p>
<p>Z-Image的训练过程并非简单的“数据投喂”，而是一个精心设计的、分阶段的“课程”，旨在系统性地构建和优化模型能力。整个流程好比一个人的成长与教育过程：从通识教育打下基础，到专业深造拓展能力，再到步入社会实践以对齐现实需求。</p>
<ol>
<li><strong>阶段一：低分辨率预训练 (Low-resolution Pre-training)</strong></li>
</ol>
<p> <strong>目标</strong>：此阶段是模型的“义务教育”，在<code>256x256</code>的固定低分辨率下进行。其核心目标是高效地建立基础的视觉-语义对齐能力和图像合成知识，为后续更高阶的学习打下坚实的基础。由于分辨率较低，计算成本也相对可控，使得模型能在此阶段用有限的资源学习到最广泛的概念。</p>
<ol start="2">
<li><strong>阶段二：全能预训练 (Omni-pre-training)</strong></li>
</ol>
<p> <strong>目标：进入“大学深造”阶段，模型开始接触更复杂的任务。</strong></p>
<p>这里的“全能 (Omni)”体现在三个方面：首先是<strong>任意分辨率训练</strong>，使模型具备处理不同尺寸和宽高比图像的能力；其次是<strong>文生图与图生图联合训练</strong>，将图像编辑能力与生成能力一并培养；最后是<strong>多层次双语文本描述训练</strong>，确保模型深刻理解不同粒度的文本指令。这种多任务联合训练的策略，通过“任务摊销”的方式，极大地提升了预训练预算的利用效率。</p>
<ol start="3">
<li><strong>阶段三：监督微调 (SFT)</strong></li>
</ol>
<p><strong>目标：此阶段好比“职业技能培训”，其核心目标从“最大化生成多样性”转向“最大化生成质量”，即将模型的生成分布收窄至一个专注、高保真的子流形上。</strong></p>
<p>为实现此目标，训练数据以经过严格筛选的高质量图文对为主。同时，为防止在追求高质量时遗忘掉不常见的概念，该阶段特别采用了“<strong>概念平衡</strong>”采样策略，动态调整训练数据中长尾概念的权重，有效避免了<strong>灾难性遗忘</strong>。</p>
<ol start="4">
<li><strong>阶段四：人类反馈强化学习 (RLHF)</strong></li>
</ol>
<p><strong>目标：这是模型“步入社会”的最后一步，旨在弥合模型生成结果与真实人类偏好之间的细微差距。</strong></p>
<p><strong>Z-Image采用了一种精妙的两步策略：首先，使用</strong>直接偏好优化 (DPO)** 进行离线对齐，重点解决如<strong>文本渲染、对象计数</strong>等具有<strong>客观</strong>评判标准的问题；随后，采用<strong>组相对策略优化 (GRPO)</strong> 进行在线微调，进一步优化<strong>审美、照片真实感</strong>等更<strong>主观</strong>的质量维度。</p>
<p>从训练过程的中间结果可以直观地看到，模型在每个阶段都取得了显著的进步。预训练阶段建立了基本的图像结构和语义关联，SFT阶段大幅提升了图像的精细度和美学质量，而RLHF阶段则进一步增强了图像的真实感和对复杂指令的遵循能力。</p>
<p>经过这套多阶段的精心训练，Z-Image已具备强大的生成能力。然而，为了满足实际应用中对实时性的严苛要求，还必须攻克最后一个难题——推理效率。</p>
<h3 id="（4）极速推理-——-Z-Image-Turbo的诞生"><a href="#（4）极速推理-——-Z-Image-Turbo的诞生" class="headerlink" title="（4）极速推理 —— Z-Image-Turbo的诞生"></a>（4）极速推理 —— Z-Image-Turbo的诞生</h3><p>尽管基础模型已足够强大，但其生成一张高质量图像通常需要约100次函数评估（Number of Function Evaluations，NFE），这对于追求实时交互的应用场景而言是无法接受的。因此，如何在不牺牲甚至提升视觉质量的前提下，将推理步骤从近百步大幅压缩至个位数，成为Z-Image走向实用化的关键。Z-Image-Turbo的诞生，正是为了解决这一核心矛盾。</p>
<p>Z-Image-Turbo的高效推理能力主要源于两项在知识蒸馏领域的关键技术创新：</p>
<p>• <strong>解耦分布匹配蒸馏 (Decoupled DMD)</strong> 。传统的分布匹配蒸馏（DMD）方法在实践中常常导致生成图像的细节丢失和色彩偏移。Z-Image团队深入研究后洞察到，DMD的成功实际上源于两种可分离的机制：作为主要驱动力的<strong>“CFG增强（CFG-Augmentation, CA）”</strong>负责提升生成能力，而作为稳定器的<strong>“分布匹配（Distribution Matching, DM）”</strong>则确保训练过程稳定。基于此，他们提出了Decoupled DMD技术，通过解耦并分别为这两个机制设计最优的训练策略，从根本上解决了传统DMD方法中常见的细节模糊和色彩失真问题。</p>
<p>• <strong>结合强化学习的DMDR</strong>。 为了进一步提升模型的审美和对人类偏好的对齐度，团队巧妙地将强化学习（RL）与蒸馏过程相结合，提出了DMDR（Distribution Matching Distillation meets Reinforcement Learning）框架。该方法的核心思想是，利用分布匹配（DM）项作为一个强大的<strong>“内在正则化器”</strong>，与强化学习的奖励目标协同优化。这使得模型在努力对齐人类偏好的同时，能够有效避免“刷分”（reward hacking）——即模型为了获得高分而生成视觉上不合理或扭曲的图像——从而确保了生成结果的稳定与高质量。</p>
<p>一系列优化的效果是显著的。原始的SFT模型质量高但速度慢；标准的DMD虽然快，但出现了明显的细节模糊；Decoupled DMD成功恢复了细节和色彩保真度；而最终的Z-Image-Turbo，即D-DMD与DMDR的结合体，在仅需8步推理的情况下，其感知质量甚至超越了需要100步推理的教师模型。</p>
<p>至此，Z-Image-Turbo成功实现了在企业级GPU上的亚秒级推理，并能兼容显存小于16GB的消费级硬件，完美解决了推理速度与视觉保真度之间的长期矛盾。</p>
<p><img src="/2025/12/08/Z-Image/6.PNG"></p>
<h2 id="性能评估：Z-Image在公开基准上的表现"><a href="#性能评估：Z-Image在公开基准上的表现" class="headerlink" title="性能评估：Z-Image在公开基准上的表现"></a>性能评估：Z-Image在公开基准上的表现</h2><h3 id="人类偏好评估：AI-Arena的胜利"><a href="#人类偏好评估：AI-Arena的胜利" class="headerlink" title="人类偏好评估：AI Arena的胜利"></a>人类偏好评估：AI Arena的胜利</h3><p>在所有评估中，由大规模真人进行双盲投票的偏好评估最具说服力。在公开、独立的基准测试平台 <strong>AI Arena</strong> 上，Z-Image-Turbo与全球顶尖的开源及闭源模型进行了直接对决。结果显示，Z-Image-Turbo取得了 <strong>全球第四、开源模型第一</strong> 的优异成绩。其Elo分数（一种衡量相对技能水平的评级系统）不仅超越了所有其他开源模型，甚至超过了多个知名的闭源商业模型，充分证明了其生成结果获得了广泛的人类认可。</p>
<p><img src="/2025/12/08/Z-Image/7.PNG"></p>
<h3 id="自动化基准测试：全面领先"><a href="#自动化基准测试：全面领先" class="headerlink" title="自动化基准测试：全面领先"></a>自动化基准测试：全面领先</h3><p>在一系列自动化评测基准上，Z-Image同样展现出全面的领先优势：</p>
<p>• <strong>双语文本渲染</strong> 综合<code>CVTG-2K</code>和<code>LongText-Bench</code>两大权威文本渲染基准测试的结果，Z-Image在处理复杂的中英文长文本和多区域文本渲染任务上，准确率均达到了<strong>SOTA（State-of-the-Art）</strong> 水平。这一结果凸显了模型在文本渲染这一公认的生成模型高难度领域中的顶尖实力。</p>
<p>• <strong>细粒度指令遵循</strong> 在<code>OneIG</code>和<code>TIIF</code>等专注于评估模型对复杂、多维度指令理解能力的基准上，Z-Image的表现同样出色。它在对齐度、推理、风格等多项指标上均名列前茅，证明了其能够精准地理解和执行包含多个约束条件的复杂用户提示。</p>
<p>• <strong>图像编辑能力</strong> 根据<code>ImgEdit</code>和<code>GEdit</code>的评测数据，衍生模型Z-Image-Edit在物体添加&#x2F;移除、风格转换、背景替换等多种编辑任务上，均展现出与顶尖编辑模型相媲美的强大竞争力，特别是在双语指令编辑方面表现突出。</p>
<p><img src="/2025/12/08/Z-Image/9.PNG"></p>
<h2 id="结论与展望：迈向高效能AIGC的新范式"><a href="#结论与展望：迈向高效能AIGC的新范式" class="headerlink" title="结论与展望：迈向高效能AIGC的新范式"></a>结论与展望：迈向高效能AIGC的新范式</h2><ul>
<li><p>Z-Image系列模型的推出，为整个AIGC社区提供了一套完整的、可复现的<strong>“蓝图”</strong>。这套蓝图雄辩地证明了，在不依赖于海量参数和近乎无限计算资源的前提下，通过对数据、架构、训练和推理等环节进行系统性的端到端优化，同样可以打造出世界一流的生成模型。</p>
</li>
<li><p>Z-Image的成功，预示着AIGC领域可能正迎来一个新的发展范式。它有望推动行业从“唯规模论”的单一路径，转向更加注重效率和创新的多元化发展。这不仅将催生出更多易于访问、成本友好且性能卓越的生成模型，更将极大地促进技术的民主化，让更多中小型企业、研究机构和个人开发者能够参与到这场AI创新的浪潮中。</p>
</li>
<li><p>论文未提及训练数据集的规模，感觉至少在亿的规模吧。</p>
</li>
</ul>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2025/02/09/r1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Coder4nlp">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Coder4nlp's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Coder4nlp's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2025/02/09/r1/" class="post-title-link" itemprop="url">r1</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2025-02-09 18:46:59" itemprop="dateCreated datePublished" datetime="2025-02-09T18:46:59+08:00">2025-02-09</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/04/17/InternLM-XComposer2-4KHD-md/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Coder4nlp">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Coder4nlp's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Coder4nlp's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/04/17/InternLM-XComposer2-4KHD-md/" class="post-title-link" itemprop="url">InternLM-XComposer2-4KHD A Pioneering Large Vision-Language Model Handling Resolutions from 336 Pixels to 4K HD</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-04-17 18:52:02 / Modified: 23:34:51" itemprop="dateCreated datePublished" datetime="2024-04-17T18:52:02+08:00">2024-04-17</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>论文：<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2404.06512">https://arxiv.org/abs/2404.06512</a><br>Github:：<a target="_blank" rel="noopener" href="https://github.com/InternLM/InternLM-XComposer">https://github.com/InternLM/InternLM-XComposer</a></p>
<p>大型视觉-语言模型(LVLM)领域已经取得了重大进展，但由于分辨率有限，在理解细粒度视觉内容方面的挑战阻碍了其进展。最近的努力旨在增强LVLMs的高分辨率理解能力，但它们仍然限制在大约1500 × 1500像素，并限制在相对狭窄的分辨率范围内。本文提出了InternLMXComposer2-4KHD，这是将LVLM分辨率提升到4K高清(3840 × 1600)及以上的开创性探索。同时，考虑到并非所有场景都需要超高分辨率，它支持从336像素到4K标准的多种分辨率，极大地拓宽了其适用范围。具体而言，该研究通过引入一种新颖的扩展：基于自动patch配置的动态解析来推进patch划分范式。它在保持训练图像宽高比的同时，根据预训练的视觉Transformer (ViT) (336 × 336)自动改变patch计数和配置布局，从而实现从336像素到4K标准的动态训练分辨率。我们的研究表明，将训练分辨率扩大到4K高清，可以在不触及潜在改进上限的情况下实现持续的性能增强。InternLM-XComposer2-4KHD表现出卓越的能力，在16个基准测试中的10个测试中匹配甚至超过GPT4V和Gemini Pro。具有7B参数的InternLM-XComposer2-4KHD模型系列在<a target="_blank" rel="noopener" href="https://github.com/InternLM/InternLM-XComposer%E5%8F%AF%E7%94%A8%E3%80%82">https://github.com/InternLM/InternLM-XComposer可用。</a></p>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2024/04/17/InternLM-XComposer2-4KHD-md/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2024/01/21/git-443%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Coder4nlp">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Coder4nlp's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Coder4nlp's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2024/01/21/git-443%E9%97%AE%E9%A2%98%E8%A7%A3%E5%86%B3/" class="post-title-link" itemprop="url">git 443问题解决</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2024-01-21 23:45:41 / Modified: 23:58:34" itemprop="dateCreated datePublished" datetime="2024-01-21T23:45:41+08:00">2024-01-21</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="问题"><a href="#问题" class="headerlink" title="问题"></a>问题</h2><p>​	由于特殊原因，使用Git访问Github时，比如使用<code>git clone，git push...</code>可能常会出现443问题： fatal: unable to access ‘<a target="_blank" rel="noopener" href="https://github.com/tmp.git/">https://github.com/tmp.git/</a>‘: Failed to connect to github.com port 443 after 21044 ms: Timed out。443是HTTP协议中的一个端口号，用于安全的HTTPS通信。然后，浏览器是可以通过梯子访问的。这是由于浏览器配置了代理来访问Github，但是git没有使用。</p>
<h2 id="解决"><a href="#解决" class="headerlink" title="解决"></a>解决</h2><p>通过如下方式配置<code>Git</code>代理</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">git config --global http.proxy &quot;127.0.0.1:port&quot;  </span><br><span class="line">git config --global https.proxy &quot;127.0.0.1:port&quot;</span><br></pre></td></tr></table></figure>

<p><strong>其中的port需要替换为代理的端口号</strong></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/17/vscode%E9%85%8D%E7%BD%AEdeepspeed%E8%BF%9B%E8%A1%8Cdebug/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Coder4nlp">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Coder4nlp's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Coder4nlp's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/17/vscode%E9%85%8D%E7%BD%AEdeepspeed%E8%BF%9B%E8%A1%8Cdebug/" class="post-title-link" itemprop="url">vscode配置deepspeed进行debug</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2023-10-17 19:54:15 / Modified: 20:01:42" itemprop="dateCreated datePublished" datetime="2023-10-17T19:54:15+08:00">2023-10-17</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>Visual Studio Code的一个关键特性是它强大的调试支持。VS Code的内置调试器有助于加速你的编辑、编译和调试过程。</p>
<h2 id="安装环境"><a href="#安装环境" class="headerlink" title="安装环境"></a>安装环境</h2><p>首先需要安装<code>Python</code>环境，如果是<code>Vscode</code>远程连接服务器，那么要<code>Python</code>插件安装到远程服务器中。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ol>
<li><a target="_blank" rel="noopener" href="https://code.visualstudio.com/docs/editor/debugging">Debugging</a></li>
</ol>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/10/15/Pytorch%E4%B8%AD%E7%9A%84data%E5%92%8Cdetach%E5%AF%B9%E6%AF%94/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Coder4nlp">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Coder4nlp's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Coder4nlp's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/10/15/Pytorch%E4%B8%AD%E7%9A%84data%E5%92%8Cdetach%E5%AF%B9%E6%AF%94/" class="post-title-link" itemprop="url">Pytorch中的data和detach对比</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-10-15 17:09:17" itemprop="dateCreated datePublished" datetime="2023-10-15T17:09:17+08:00">2023-10-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-16 00:12:41" itemprop="dateModified" datetime="2023-10-16T00:12:41+08:00">2023-10-16</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h2 id="1-data的使用"><a href="#1-data的使用" class="headerlink" title="1 .data的使用"></a>1 <code>.data</code>的使用</h2><p><code>.data</code>是从变量（Variable）中获取张量的主要方法。</p>
<p>在Pytorch 0.4之前，被<code>torch.autograd.Variable</code>包裹的<code>Tensor</code>才能实现反向传播。</p>
<p> <code>Varibale</code>包含的几个属性</p>
<ul>
<li><code>data</code>：存储了Tensor，是本体数据；</li>
<li><code>grad</code>：保存&#x2F;累加data的梯度，本身是个Variable而非Tensor，与data形状一致；</li>
<li><code>grad_fn</code>：指向Function对象，用于反向传播的梯度计算之用；</li>
<li><code>requires_grad(bool)</code>：表示是否需要求梯度，默认为false；</li>
<li><code>volatile(bool)</code>：如果某一个variable的volatile属性被设为True，那么所有依赖它的节点volatile属性都为True。volatile属性为True的节点不会求导，volatile的优先级比requires_grad高，默认为False。</li>
</ul>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2023/10/15/Pytorch%E4%B8%AD%E7%9A%84data%E5%92%8Cdetach%E5%AF%B9%E6%AF%94/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/08/22/einops%E5%BA%93%E4%BB%8B%E7%BB%8D/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Coder4nlp">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Coder4nlp's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Coder4nlp's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/08/22/einops%E5%BA%93%E4%BB%8B%E7%BB%8D/" class="post-title-link" itemprop="url">einops库介绍</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2023-08-22 23:44:49" itemprop="dateCreated datePublished" datetime="2023-08-22T23:44:49+08:00">2023-08-22</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2023-10-15 23:53:35" itemprop="dateModified" datetime="2023-10-15T23:53:35+08:00">2023-10-15</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="einops库介绍"><a href="#einops库介绍" class="headerlink" title="einops库介绍"></a>einops库介绍</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>einops是一个灵活且强大的操作张量的库，支持numpy，pytorch，TensorFlow，jax等。下面介绍一些三个常用的函数：rearrange，reduce, repeat。</p>
<h2 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h2><p>使用pip进行安装</p>
<figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip install einops</span><br></pre></td></tr></table></figure>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2023/08/22/einops%E5%BA%93%E4%BB%8B%E7%BB%8D/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/04/23/Python%E4%B8%AD%E7%9A%84ChainMap/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Coder4nlp">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Coder4nlp's Blog">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | Coder4nlp's Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2023/04/23/Python%E4%B8%AD%E7%9A%84ChainMap/" class="post-title-link" itemprop="url">Python中的ChainMap</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>
      

      <time title="Created: 2023-04-23 22:21:06 / Modified: 22:37:33" itemprop="dateCreated datePublished" datetime="2023-04-23T22:21:06+08:00">2023-04-23</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="ChainMap介绍"><a href="#ChainMap介绍" class="headerlink" title="ChainMap介绍"></a>ChainMap介绍</h1><p><code>collections.ChainMap</code>用于快速链接多个映射，并将它们视为一个单元。它通常比创建一个新字典并运行多次<code>update()</code>调用要快得多。</p>
<p><code>ChainMap</code>的作用：</p>
<ul>
<li><code>ChainMap</code>将多个字典或其他映射组合在一起，以创建一个可更新的单一视图。如果没有指定映射，则提供一个空字典，以便新链始终至少有一个映射。</li>
<li>底层映射存储在一个列表中。该列表是公共的，可以使用maps属性访问或更新。</li>
<li>查找时，依次搜索底层映射，直到找到一个键。<strong>但是，写、更新和删除只对第一个映射进行操作！！！</strong></li>
<li><code>ChainMap</code>通过引用合并底层映射。因此，如果某个底层映射更新了，这些更改将反映在<code>ChainMap</code>中。</li>
<li>支持所有常用的字典方法。</li>
</ul>
          <!--noindex-->
            <div class="post-button">
              <a class="btn" href="/2023/04/23/Python%E4%B8%AD%E7%9A%84ChainMap/#more" rel="contents">
                Read more &raquo;
              </a>
            </div>
          <!--/noindex-->
        
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">


<div class="copyright">
  &copy; 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Coder4nlp</span>
</div>
<div class="busuanzi-count">
    <span class="post-meta-item" id="busuanzi_container_site_uv">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="Total Visitors">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-item" id="busuanzi_container_site_pv">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="Total Views">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

    </div>
  </footer>

  
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>




  <script src="/js/third-party/pace.js"></script>

  
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>




  

  <script class="next-config" data-name="enableMath" type="application/json">false</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
